Control Plane Plan for freqkflag.co


Phase 0 — Baseline + Service Registry (PHASE-00)

Goal: Have a single, machine-readable source of truth for all services, and confirm the current infra layout matches reality.

Tasks
	•	Create /root/infra/SERVICES.yml (or .json) with entries like:

services:
  - id: traefik
    name: Traefik
    dir: /root/infra/traefik
    url: null
    type: infra
    depends_on: []
  - id: wikijs
    name: WikiJS
    dir: /root/infra/wikijs
    url: https://wiki.freqkflag.co
    type: app
    depends_on: [traefik, postgres]

	•	For each service in the cookbook, add:
	•	id, name, dir, url, type (infra/app/db), depends_on
	•	Verify /root/infra/ actually contains what the cookbook says (traefik, vault, wikijs, wordpress, linkstack, etc.).

Done When
	•	SERVICES.yml exists and includes all services in the cookbook.
	•	Paths, domains, and statuses match what’s described.

⸻

Phase 1 — Routing & Access Baseline (PHASE-01)

Goal: Traefik + Cloudflared + DNS are clean and predictable. No phantom paths, no “it works locally but not over HTTPS.”

Tasks
	1.	Confirm Traefik network and ports
	•	Check:

docker ps | grep traefik
docker network ls | grep traefik
docker logs traefik --tail=100


	2.	Confirm Cloudflared hookup
	•	Find its stack and inspect:

docker ps | grep cloudflared
docker logs cloudflared --tail=100


	•	Make sure:
	•	It talks to Traefik, not individual apps.
	•	Ingress rules in Cloudflare match domains in the cookbook.

	3.	Standardize every web service
	•	Each docker-compose.yml:
	•	On traefik-network (or whatever you choose as the shared network).
	•	Has Traefik labels for Host() + TLS.
	4.	Write a tiny “routing sanity” script
	•	/root/infra/scripts/infra-routing-check.sh:
	•	Pings each URL from the VPS (curl -k).
	•	Returns a compact status table.

Done When
	•	Hitting each domain in the “Service URLs” table works over HTTPS.
	•	One command (infra-routing-check.sh) gives you a quick “is routing okay?” answer.

⸻

Phase 2 — First-Run & Lifecycle of All Services (PHASE-02)

Goal: Every defined service can start, stop, and restart cleanly with known dependencies and health checks.

Tasks
	1.	Standard start/stop script
	•	Create /root/infra/scripts/infra-service.sh:

./infra-service.sh start wikijs
./infra-service.sh stop wordpress
./infra-service.sh restart vault


	•	Script reads SERVICES.yml and cds into the right dir.

	2.	Bring each service online, one by one
For each service:
	•	docker compose up -d
	•	Verify with:

docker compose ps
docker compose logs --tail=100


	•	Fix any obvious config issues.

	3.	Handle special snowflakes
	•	Vault: ensure init/unseal scripts are tested.
	•	Mastodon + Mailu + Supabase: confirm all their companion containers come up and talk.
	4.	Update SERVICES.yml with current status
	•	Add status: running|configured|planned.

Done When
	•	You can start/stop/restart any service using infra-service.sh.
	•	Every “configured” service actually boots without mystery 500s / crashloops.

⸻

Phase 3 — Per-Service Runbooks & Templates (PHASE-03)

Goal: Every service has a README/runbook with exact commands, context, and common fixes.

Tasks
	1.	Create a runbook template
	•	Template fields:
	•	Purpose
	•	URLs
	•	Start/Stop commands
	•	Health checks
	•	Common issues
	•	Backup/restore notes
	•	Save as /root/infra/runbooks/TEMPLATE_SERVICE_RUNBOOK.md.
	2.	Generate runbooks for each service
	•	For each directory (traefik/, vault/, wikijs/, etc.), create README.md based on the template.
	•	Link each runbook from the cookbook and from WikiJS.
	3.	Wire runbooks into WikiJS
	•	Create a “Infra Runbooks” page in WikiJS that lists all services with deep links to each file.

Done When
	•	Every service folder has a README.md that lets you recover your memory at 3am.
	•	One WikiJS page acts as the “Infra Manual” index.

⸻

Phase 4 — Observability as Pane #1 (Grafana + Loki) (PHASE-04)

Goal: A single Grafana dashboard that shows the heartbeat of your stack: key services, logs, resources.

Tasks
	1.	Finish wiring Monitoring + Logging stacks
	•	Ensure monitoring/ and logging/ stacks are running (Prometheus, Grafana, Loki, Promtail).
	•	Verify you can hit:
	•	grafana.freqkflag.co
	•	prometheus.freqkflag.co
	•	loki.freqkflag.co
	2.	Add service-level metrics/logs
	•	Label containers for Promtail/Loki and Prometheus where applicable.
	•	Make sure logs are shipping.
	3.	Create a Grafana “Infra Overview” dashboard
Panels like:
	•	Host CPU/RAM/Disk
	•	Traefik request rate + 4xx/5xx errors
	•	“Service up/down” status (even if it’s just based on metrics/heartbeats)
	•	Loki queries for:
	•	Errors per service
	•	Last 50 logs for a service
	4.	Link Grafana from WikiJS
	•	Add a “Monitoring” section in WikiJS with direct links to:
	•	Infra dashboard
	•	Loki log Explore view.

Done When
	•	You can answer “is anything on fire right now?” from a single Grafana dashboard.
	•	Logs and metrics are accessible in 1–2 clicks.

⸻

Phase 5 — DevOps Control Plane MVP (One Pane) (PHASE-05)

Goal: A single web UI where you can see, operate, and jump into any tool. Think: ops.freqkflag.co.

You have two good approaches:

Option 1 — Node-RED / n8n Ops Console

Use what you already have.

Tasks
	•	Pick one: n8n or Node-RED as the control brain.
	•	Create flows for:
	•	Start/Stop/Restart a service (SSH → infra-service.sh).
	•	Trigger backups (docker compose run --rm backup).
	•	Run image scan script (scan-images.sh).
	•	Build a small Dashboard:
	•	Dropdown: select service (from SERVICES.yml)
	•	Buttons: Start / Stop / Restart
	•	Button: View docs (link to WikiJS page)
	•	Button: View metrics (link to Grafana panel)
	•	Button: View logs (link to Loki Explore query)

Result: A browser dashboard that execs actions and links you to deeper views.

⸻

Option 2 — Custom “Infra Console” Micro-App

If you want a cleaner, branded UI later:

Tasks
	•	Build a tiny web app (Next.js, Phoenix, or even a minimal Node/Express app) behind Traefik at ops.freqkflag.co.
	•	Backend:
	•	Reads SERVICES.yml.
	•	Uses Docker socket or SSH + shell to run:
	•	docker ps
	•	infra-service.sh commands.
	•	Frontend:
	•	Table of services:
	•	Name, status, type
	•	Buttons: Start / Stop / Restart
	•	Links: Docs, Metrics, Logs
	•	Auth via basic auth or OAuth later.

Result: A fully custom, dark-neon “Control Plane” that’s future-proof.

⸻

Phase 5 Done When
	•	There is one URL (e.g., ops.freqkflag.co) where you can:
	•	See all services + their status.
	•	Perform lifecycle actions for a service.
	•	Jump to docs/metrics/logs with a click.

That’s your one plane of glass.

⸻

Phase 6 — Extensions & Polish (PHASE-06)

Goal: Make it comfy, modular, and safe as you grow.

Ideas
	•	Service scaffolder script
	•	./scripts/infra-new-service.sh myapp:
	•	Creates folder structure.
	•	Adds basic docker-compose.yml.
	•	Adds entry to SERVICES.yml.
	•	Creates stub README/runbook.
	•	Alerting
	•	Prometheus alert rules for:
	•	Service down
	•	High CPU/disk
	•	Notifications to email/Matrix/Discord.
	•	RBAC / multi-user
	•	If you ever add collaborators, lock down ops.freqkflag.co with SSO/OAuth or at least strong basic auth.
	•	Visual flair
	•	Make the ops console match your dark-neon brand:
	•	Magenta/cyan highlights.
	•	Panels for “Infra Health,” “Logs Heatmap,” “Recent Incidents.”

⸻

